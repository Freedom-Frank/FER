# å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ å¿«é€Ÿå¼€å§‹ä½¿ç”¨ FER2013 é¢éƒ¨è¡¨æƒ…è¯†åˆ«é¡¹ç›®ã€‚

## ç›®å½•

- [å®‰è£…ç¯å¢ƒ](#å®‰è£…ç¯å¢ƒ)
- [å‡†å¤‡æ•°æ®](#å‡†å¤‡æ•°æ®)
- [å¿«é€Ÿè®­ç»ƒ](#å¿«é€Ÿè®­ç»ƒ)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [æ¨ç†é¢„æµ‹](#æ¨ç†é¢„æµ‹)
- [ä¸‹ä¸€æ­¥](#ä¸‹ä¸€æ­¥)

## å®‰è£…ç¯å¢ƒ

### Windows (CPU)

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. éªŒè¯å®‰è£…
python -c "import mindspore; print('MindSpore version:', mindspore.__version__)"
```

### Linux/WSL2 (GPU)

å¦‚æœéœ€è¦GPUåŠ é€Ÿ,è¯·å‚è€ƒ [ç¯å¢ƒé…ç½®æŒ‡å—](setup.md#wsl2-gpu-é…ç½®)ã€‚

## å‡†å¤‡æ•°æ®

ç¡®ä¿ FER2013 æ•°æ®é›†å·²æ”¾ç½®åœ¨æ­£ç¡®ä½ç½®:

```
data/FER2013/fer2013.csv
```

æ•°æ®é›†å¯ä»¥ä» [Kaggle](https://www.kaggle.com/datasets/msambare/fer2013) ä¸‹è½½ã€‚

## å¿«é€Ÿè®­ç»ƒ

### æ–¹æ¡ˆ A: CPU è®­ç»ƒ(å¿«é€Ÿæµ‹è¯•)

é€‚åˆå¿«é€ŸéªŒè¯ä»£ç æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

```bash
# å¿«é€Ÿæµ‹è¯•(2ä¸ªepoch)
python src/train.py \
  --data_csv data/FER2013/fer2013.csv \
  --device_target CPU \
  --batch_size 32 \
  --epochs 2 \
  --augment

# å®Œæ•´è®­ç»ƒ(50ä¸ªepoch)
python src/train.py \
  --data_csv data/FER2013/fer2013.csv \
  --device_target CPU \
  --batch_size 32 \
  --epochs 50 \
  --augment
```

**é¢„è®¡æ—¶é—´**: æ¯ä¸ª epoch çº¦ 15-20 åˆ†é’Ÿ

### æ–¹æ¡ˆ B: GPU è®­ç»ƒ(æ¨è)

é€Ÿåº¦å¿« 5-10 å€,é€‚åˆå®Œæ•´è®­ç»ƒã€‚

```bash
# å¿«é€Ÿæµ‹è¯•(2ä¸ªepoch)
python src/train.py \
  --data_csv data/FER2013/fer2013.csv \
  --device_target GPU \
  --batch_size 64 \
  --epochs 2 \
  --augment

# å®Œæ•´ä¼˜åŒ–è®­ç»ƒ(200ä¸ªepoch)
python src/train.py \
  --data_csv data/FER2013/fer2013.csv \
  --device_target GPU \
  --batch_size 96 \
  --epochs 200 \
  --lr 7e-4 \
  --patience 30 \
  --weight_decay 3e-5 \
  --label_smoothing 0.12 \
  --augment \
  --mixup \
  --mixup_alpha 0.4
```

**é¢„è®¡æ—¶é—´**: æ¯ä¸ª epoch çº¦ 1-2 åˆ†é’Ÿ

### ä½¿ç”¨ Windows æ‰¹å¤„ç†è„šæœ¬

```bash
# è¿è¡Œé¢„é…ç½®çš„è®­ç»ƒè„šæœ¬
scripts\run_train.bat
```

## è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | æ¨èå€¼ |
|------|------|--------|--------|
| `--data_csv` | æ•°æ®é›†è·¯å¾„ | å¿…éœ€ | - |
| `--device_target` | è®¾å¤‡ç±»å‹ | CPU | GPU(å¦‚å¯ç”¨) |
| `--batch_size` | æ‰¹æ¬¡å¤§å° | 64 | CPU:32, GPU:96 |
| `--epochs` | è®­ç»ƒè½®æ•° | 100 | æµ‹è¯•:2-10, å®Œæ•´:200 |
| `--lr` | å­¦ä¹ ç‡ | 1e-3 | 7e-4 |
| `--patience` | æ—©åœè€å¿ƒå€¼ | 15 | 30 |
| `--augment` | æ•°æ®å¢å¼º | False | True(æ¨è) |
| `--mixup` | Mixupå¢å¼º | False | True(é«˜çº§) |
| `--mixup_alpha` | Mixupå¼ºåº¦ | 0.2 | 0.4 |

## è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```
============================================================
Training Configuration:
  Device: GPU
  Batch size: 96
  Epochs: 200
  Learning rate: 0.0007
  Data augmentation: True
  Mixup: True (alpha=0.4)
============================================================

Loading datasets...
Training batches: 374
Validation batches: 37

Building model...

Starting training...
============================================================
epoch: 1 step: 374, loss is 1.8245
Epoch 1 - Validation Accuracy: 0.4821

epoch: 2 step: 374, loss is 1.7123
Epoch 2 - Validation Accuracy: 0.5234
...
epoch: 85 step: 374, loss is 0.9234
Epoch 85 - Validation Accuracy: 0.7589  <- Best!

Early stopping triggered!
Best validation accuracy: 0.7589 at epoch 85
============================================================
```

## æ¨¡å‹è¯„ä¼°

è®­ç»ƒå®Œæˆå,è¯„ä¼°æ¨¡å‹æ€§èƒ½:

```bash
python src/eval.py \
  --data_csv data/FER2013/fer2013.csv \
  --ckpt_path checkpoints/final_model.ckpt \
  --device_target GPU
```

è¾“å‡ºç¤ºä¾‹:

```
Loading model from checkpoints/final_model.ckpt
Evaluating on test set...
Test Accuracy: 75.89%

Per-class accuracy:
  Angry: 72.3%
  Disgust: 68.5%
  Fear: 71.2%
  Happy: 86.4%
  Sad: 73.8%
  Surprise: 81.2%
  Neutral: 77.9%
```

## æ¨ç†é¢„æµ‹

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹:

```bash
python src/inference.py \
  --ckpt_path checkpoints/final_model.ckpt \
  --image_path path/to/your/image.jpg
```

è¾“å‡ºç¤ºä¾‹:

```
Loading model from checkpoints/final_model.ckpt
Processing image: path/to/your/image.jpg

Prediction Results:
  Predicted emotion: Happy (3)
  Confidence: 92.45%

All probabilities:
  Angry: 1.2%
  Disgust: 0.3%
  Fear: 2.1%
  Happy: 92.5%
  Sad: 1.5%
  Surprise: 1.8%
  Neutral: 0.6%
```

## æ€§èƒ½å¯¹æ¯”

| é…ç½® | è®­ç»ƒæ—¶é—´/epoch | 100 epochs æ€»æ—¶é—´ | é¢„æœŸå‡†ç¡®ç‡ |
|------|---------------|------------------|-----------|
| **CPU** | 15-20åˆ†é’Ÿ | 25-33å°æ—¶ | ~66-70% |
| **GPU** | 1-2åˆ†é’Ÿ | 2-3å°æ—¶ | ~74-77% |

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ?

```bash
# Linux/WSL2
watch -n 1 nvidia-smi

# æˆ–åœ¨è®­ç»ƒçš„å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
nvidia-smi
```

### Q2: è®­ç»ƒä¸­æ–­å¦‚ä½•æ¢å¤?

æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜æœ€ä½³ checkpoint åˆ° `checkpoints/` ç›®å½•ã€‚å¦‚æœè®­ç»ƒä¸­æ–­,å¯ä»¥ä»æœ€æ–°çš„ checkpoint ç»§ç»­è®­ç»ƒ(éœ€è¦ä¿®æ”¹è®­ç»ƒè„šæœ¬æ·»åŠ åŠ è½½ checkpoint çš„ä»£ç )ã€‚

### Q3: å¦‚ä½•è°ƒæ•´æ¨¡å‹ä»¥é€‚åº”å†…å­˜é™åˆ¶?

å‡å° `batch_size`:
```bash
# ä» 96 é™åˆ° 64
--batch_size 64

# æˆ–é™åˆ° 32
--batch_size 32
```

### Q4: å¦‚ä½•æé«˜è®­ç»ƒé€Ÿåº¦?

1. ä½¿ç”¨ GPU è®­ç»ƒ
2. å¢åŠ  `batch_size` (å¦‚æœå†…å­˜å…è®¸)
3. å‡å°‘æ•°æ®å¢å¼º(å»æ‰ `--augment` æˆ– `--mixup`)
4. ä½¿ç”¨æ›´å°‘çš„è®­ç»ƒè½®æ•°

### Q5: å‡†ç¡®ç‡ä¸ç†æƒ³æ€ä¹ˆåŠ?

1. ç¡®ä¿å¯ç”¨æ•°æ®å¢å¼º: `--augment`
2. ä½¿ç”¨ Mixup: `--mixup --mixup_alpha 0.4`
3. å¢åŠ è®­ç»ƒè½®æ•°: `--epochs 200`
4. è°ƒæ•´å­¦ä¹ ç‡: `--lr 7e-4`
5. å‚è€ƒ [æ¨¡å‹ä¼˜åŒ–è¯´æ˜](optimization.md) è¿›è¡Œæ·±å…¥ä¼˜åŒ–

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [ç¯å¢ƒé…ç½®æŒ‡å—](setup.md) äº†è§£è¯¦ç»†çš„ç¯å¢ƒé…ç½®
- ğŸ”§ æŸ¥çœ‹ [æ¨¡å‹ä¼˜åŒ–è¯´æ˜](optimization.md) äº†è§£æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯
- ğŸ“Š å‚è€ƒ [ç‰ˆæœ¬æ›´æ–°è®°å½•](changelog.md) äº†è§£å„ç‰ˆæœ¬æ”¹è¿›

## æ¨èå·¥ä½œæµç¨‹

1. **é¦–æ¬¡è¿è¡Œ**: CPU å¿«é€Ÿæµ‹è¯•(2 epochs)éªŒè¯ç¯å¢ƒ
2. **ç¯å¢ƒé…ç½®**: é…ç½® WSL2 GPU ç¯å¢ƒ(ä¸€æ¬¡æ€§å·¥ä½œ)
3. **åˆæ­¥è®­ç»ƒ**: GPU ä¸­ç­‰è®­ç»ƒ(50 epochs)
4. **å®Œæ•´è®­ç»ƒ**: GPU å®Œæ•´è®­ç»ƒ(200 epochs,å¯ç”¨æ‰€æœ‰ä¼˜åŒ–)
5. **æ¨¡å‹è°ƒä¼˜**: æ ¹æ®ç»“æœè°ƒæ•´è¶…å‚æ•°

ç¥è®­ç»ƒé¡ºåˆ©! ğŸ‰
